# <img width="40" alt="tool icon" src="https://github.com/user-attachments/assets/f9b86465-aefa-4625-a09b-54e158efcf96" />  Notebook to convert LLM safetensors to fp8 with LLM Compressor for vLLM

Convert any LLM from `*.safetensors` and tokenizers to `fp8` Weight and Activation Quantization, with [LLM Compression](https://github.com/vllm-project/llm-compressor)
